{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restricted Botlzman Machines (RBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Tuple, Literal, Optional, Union, Iterable\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from tqdm import tqdm\n",
    "from numpy._typing import ArrayLike\n",
    "\n",
    "ArrayLike = Union[List, Tuple, np.ndarray]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"../data/\"\n",
    "ALPHA_DIGIT_PATH = os.path.join(DATA_FOLDER, \"binaryalphadigs.mat\")\n",
    "MNIST_PATH = os.path.join(DATA_FOLDER, \"mnist_all.mat\")\n",
    "\n",
    "if not os.path.exists(ALPHA_DIGIT_PATH):\n",
    "    raise FileNotFoundError(f\"The file {ALPHA_DIGIT_PATH} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Implementing a RBM and testing on Binary AlphaDigits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Labels</th>\n",
       "      <th>Class Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>C</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>D</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>E</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>F</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>G</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>H</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>J</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>K</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>L</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>N</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>O</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>P</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Q</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>R</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>S</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>T</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>U</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>V</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>W</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>X</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Y</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Z</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Labels  Class Count\n",
       "0             0           39\n",
       "1             1           39\n",
       "2             2           39\n",
       "3             3           39\n",
       "4             4           39\n",
       "5             5           39\n",
       "6             6           39\n",
       "7             7           39\n",
       "8             8           39\n",
       "9             9           39\n",
       "10            A           39\n",
       "11            B           39\n",
       "12            C           39\n",
       "13            D           39\n",
       "14            E           39\n",
       "15            F           39\n",
       "16            G           39\n",
       "17            H           39\n",
       "18            I           39\n",
       "19            J           39\n",
       "20            K           39\n",
       "21            L           39\n",
       "22            M           39\n",
       "23            N           39\n",
       "24            O           39\n",
       "25            P           39\n",
       "26            Q           39\n",
       "27            R           39\n",
       "28            S           39\n",
       "29            T           39\n",
       "30            U           39\n",
       "31            V           39\n",
       "32            W           39\n",
       "33            X           39\n",
       "34            Y           39\n",
       "35            Z           39"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _load_data(file_path: str) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Load Binary AlphaDigits data from a .mat file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): Path to the .mat file containing the data.\n",
    "\n",
    "    Returns:\n",
    "    - data (dict): Loaded data dictionary.\n",
    "    \"\"\"\n",
    "    if file_path is None:\n",
    "        raise ValueError(\"File path must be provided.\")\n",
    "\n",
    "    return scipy.io.loadmat(file_path)\n",
    "\n",
    "\n",
    "data = _load_data(ALPHA_DIGIT_PATH)\n",
    "class_labels = data[\"classlabels\"].flatten() \n",
    "class_count = data[\"classcounts\"].flatten()\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Class Labels\": class_labels,\n",
    "        \"Class Count\": class_count\n",
    "    }\n",
    ")\n",
    "df[\"Class Labels\"] = df[\"Class Labels\"].apply(lambda x: x[0])\n",
    "df[\"Class Count\"] = df[\"Class Count\"].apply(lambda x: x[0][0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 39)\n",
      "(20, 16)\n"
     ]
    }
   ],
   "source": [
    "def _load_data(file_path: str, which: Literal[\"alphadigit\", \"mnist\"]=\"alphadigit\") -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Load Binary AlphaDigits data from a .mat file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): Path to the .mat file containing the data.\n",
    "    - which (Literal[\"alphadigit\", \"mnist\"], optional): Specifies \n",
    "        which data to load. The default value is \"alphadigit\".\n",
    "\n",
    "    Returns:\n",
    "    - data (dict): A dictionary containing the loaded data.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError: If the file_path parameter is None.\n",
    "    - ValueError: If the which parameter is not \"alphadigit\".\n",
    "\n",
    "    Example Usage:\n",
    "    ```python\n",
    "    data = _load_data(\"data.mat\", \"alphadigit\")\n",
    "    ```\n",
    "    \"\"\"\n",
    "    if file_path is None:\n",
    "        raise ValueError(\"File path must be provided.\")\n",
    "    \n",
    "    if which == \"alphadigit\":\n",
    "        return scipy.io.loadmat(file_path)[\"dat\"]\n",
    "    \n",
    "    raise ValueError(\"MNIST NOT YET AVAILABLE.\")\n",
    "\n",
    "alphadigit_data = _load_data(ALPHA_DIGIT_PATH) \n",
    "print(alphadigit_data.shape)\n",
    "print(alphadigit_data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 > map to > [0]\n",
      "10 > map to > [10]\n",
      "A > map to > [10]\n",
      "[1, 'C'] > map to > [[1], [12]]\n",
      "36 > no mapping available, out of range\n"
     ]
    }
   ],
   "source": [
    "def _map_characters_to_indices(characters: Union[str, int, List[Union[str, int]]]) -> List[int]:\n",
    "    \"\"\"\n",
    "    Map alphanumeric character to its corresponding index.\n",
    "\n",
    "    Parameters:\n",
    "    - character (str, int, list of str or int): Alphanumeric character or its index.\n",
    "\n",
    "    Returns:\n",
    "    - char_index (int): Corresponding index for the character.\n",
    "    \"\"\"\n",
    "    if isinstance(characters, list):\n",
    "        return [_map_characters_to_indices(char) for char in characters]\n",
    "    if isinstance(characters, int) and 0 <= characters <= 35:\n",
    "        return [characters]\n",
    "    if (isinstance(characters, str) and characters.isdigit()\n",
    "          and 0 <= int(characters) <= 9):\n",
    "        return [int(characters)]\n",
    "    if (isinstance(characters, str) and characters.isalpha()\n",
    "          and 'A' <= characters.upper() <= 'Z'):\n",
    "        return [ord(characters.upper()) - ord('A') + 10]\n",
    "    \n",
    "    raise ValueError(\n",
    "        \"Invalid character input. It should be an alphanumeric\" \n",
    "        \"character '[0-9|A-Z]' or its index representing '[0-35]'.\"\n",
    "    )\n",
    "\n",
    "for char in [0, 10, \"A\", [1, \"C\"], 36]:\n",
    "    try:\n",
    "        map = _map_characters_to_indices(char)\n",
    "        print(f\"{char} > map to > {map}\")\n",
    "    except:\n",
    "        print(f\"{char} > no mapping available, out of range\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def read_alpha_digit(characters: Optional[Union[str, int, List[Union[str, int]]]] = None,\n",
    "                     file_path: Optional[str] = ALPHA_DIGIT_PATH,\n",
    "                     data: Optional[Dict[str, np.ndarray]] = None,\n",
    "                     use_data: bool = False,\n",
    "                     ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Reads binary AlphaDigits data from a .mat file or uses already loaded data. \n",
    "    It extracts the data for a specified alphanumeric character or its index, and \n",
    "    flattens the images into one-dimensional vectors.\n",
    "\n",
    "    Parameters:\n",
    "    - characters (Union[str, int, List[Union[str, int]]], optional): Alphanumeric character \n",
    "        or its index whose data needs to be extracted. It can be a single character or \n",
    "        a list of characters. Default is None.\n",
    "    - file_path (str, optional): Path to the .mat file containing the data. \n",
    "        Default is None.\n",
    "    - data (dict, optional): Already loaded data dictionary. \n",
    "        Default is None.\n",
    "    - use_data (bool): Flag to indicate whether to use already loaded data.\n",
    "        Default is False.\n",
    "\n",
    "    Returns:\n",
    "    - flattened_images (numpy.ndarray): Flattened images for the specified character(s).\n",
    "    \"\"\"\n",
    "    if not use_data:\n",
    "        data = _load_data(file_path, which=\"alphadigit\")\n",
    "\n",
    "    char_indices = _map_characters_to_indices(characters)\n",
    "\n",
    "    # Select the rows corresponding to the characters indices.\n",
    "    char_data: np.ndarray = data[char_indices]\n",
    "    \n",
    "    # Flatten each image into a one-dimensional vector.\n",
    "    flattened_images = np.array([image.flatten() for image in char_data.flatten()])\n",
    "    return flattened_images\n",
    "\n",
    "def plot_characters(chars, data):\n",
    "    num_chars = len(chars)\n",
    "    num_images_per_char = data.shape[0] // num_chars\n",
    "    fig, ax = plt.subplots(1, num_chars, figsize=(num_chars * 2, 2))\n",
    "\n",
    "    for i, char in enumerate(chars):\n",
    "        # Find the index of the first image corresponding to the current char\n",
    "        start_index = i * num_images_per_char\n",
    "        image = data[start_index].reshape(20, 16)\n",
    "        ax[i].imshow(image, cmap='gray')\n",
    "        ax[i].set_title(f'Char: {char}')\n",
    "        ax[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example\n",
    "chars = [0, \"K\", 7, \"Z\"]\n",
    "data = read_alpha_digit(chars, data=data, use_data=True)\n",
    "plot_characters(chars, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (156, 320)\n"
     ]
    }
   ],
   "source": [
    "print(\"data shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM:\n",
    "    def __init__(self, n_visible: int, n_hidden: int, random_state=None) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the Restricted Boltzmann Machine.\n",
    "\n",
    "        Parameters:\n",
    "        - n_visible (int): Number of visible units.\n",
    "        - n_hidden (int): Number of hidden units.\n",
    "        - random_state: Random seed for reproducibility.\n",
    "        \"\"\"\n",
    "        self.n_visible = n_visible\n",
    "        self.n_hidden = n_hidden\n",
    "        \n",
    "        self.a = np.zeros((1, n_visible))\n",
    "        self.b = np.zeros((1, n_hidden))\n",
    "        self.rng = np.random.default_rng(random_state)\n",
    "        self.W = 1e-4 * self.rng.standard_normal(size=(n_visible, n_hidden))\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"RBM(n_visible={self.n_visible}, n_hidden={self.n_hidden})\"\n",
    "\n",
    "    def _sigmoid(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Sigmoid activation function.\n",
    "\n",
    "        Parameters:\n",
    "        - x (numpy.ndarray): Input array.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: Result of applying the sigmoid function to the input.\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def _reconstruction_error(self, input: np.ndarray, image: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Compute reconstruction error.\n",
    "\n",
    "        Parameters:\n",
    "        - input (numpy.ndarray): Original input data.\n",
    "        - image (numpy.ndarray): Reconstructed image.\n",
    "\n",
    "        Returns:\n",
    "        - float: Reconstruction error.\n",
    "        \"\"\"\n",
    "        return np.round(np.power(image - input, 2).mean(), 3)\n",
    "\n",
    "    def input_output(self, data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute hidden units given visible units.\n",
    "\n",
    "        Parameters:\n",
    "        - data (numpy.ndarray): Input data, shape (n_samples, n_visible).\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: Hidden unit activations, shape (n_samples, n_hidden).\n",
    "        \"\"\"\n",
    "        return self._sigmoid(data @ self.W + self.b)\n",
    "\n",
    "    def output_input(self, data_h: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute visible units given hidden units.\n",
    "\n",
    "        Parameters:\n",
    "        - data_h (numpy.ndarray): Hidden unit activations, shape (n_samples, n_hidden).\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: Reconstructed visible units, shape (n_samples, n_visible).\n",
    "        \"\"\"\n",
    "        return self._sigmoid(data_h @ self.W.T + self.a)\n",
    "\n",
    "    def train(self, data: np.ndarray, learning_rate: float=0.1, n_epochs: int=10, batch_size: int=10, print_each=10) -> 'RBM':\n",
    "        \"\"\"\n",
    "        Train the RBM using Contrastive Divergence.\n",
    "\n",
    "        Parameters:\n",
    "        - data (numpy.ndarray): Input data, shape (n_samples, n_visible).\n",
    "        - learning_rate (float): Learning rate for gradient descent. Default is 0.1.\n",
    "        - n_epochs (int): Number of training epochs. Default is 10.\n",
    "        - batch_size (int): Size of mini-batches. Default is 10.\n",
    "\n",
    "        Returns:\n",
    "        - RBM: Trained RBM instance.\n",
    "        \"\"\"\n",
    "        n_samples = data.shape[0]\n",
    "        for epoch in range(n_epochs):\n",
    "            self.rng.shuffle(data)\n",
    "            for i in tqdm(range(0, n_samples, batch_size), desc=f\"Epoch {epoch}\"):\n",
    "                batch = data[i:i+batch_size]\n",
    "                pos_h_probs = self.input_output(batch)\n",
    "                pos_v_probs = self.output_input(pos_h_probs)\n",
    "                neg_h_probs = self.input_output(pos_v_probs)\n",
    "                \n",
    "                # Update weights and biases\n",
    "                self.W += learning_rate * (batch.T @ pos_h_probs - pos_v_probs.T @ neg_h_probs) / batch_size\n",
    "                self.b += learning_rate * (pos_h_probs.mean(axis=0) - neg_h_probs.mean(axis=0))\n",
    "                self.a += learning_rate * (batch.mean(axis=0) - pos_v_probs.mean(axis=0))\n",
    "                \n",
    "            if epoch % print_each == 0:\n",
    "                tqdm.write(\n",
    "                    f\"Reconstruction error: {self._reconstruction_error(batch, pos_v_probs)}.\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def generate_image(self, n_samples: int=1, n_gibbs_steps: int=1) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate samples from the RBM using Gibbs sampling.\n",
    "\n",
    "        Parameters:\n",
    "        - n_samples (int): Number of samples to generate. Default is 1.\n",
    "        - n_gibbs_steps (int): Number of Gibbs sampling steps. Default is 100.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: Generated samples, shape (n_samples, n_visible).\n",
    "        \"\"\"\n",
    "        samples = np.zeros((n_samples, self.n_visible))\n",
    "        \n",
    "        # Matrix of initlization value of Gibbs samples for each sample. \n",
    "        V = self.rng.binomial(1, self.rng.random(), size=n_samples * self.n_visible).reshape((n_samples, self.n_visible))\n",
    "        for i in range(n_samples):\n",
    "            for _ in range(n_gibbs_steps):\n",
    "                h_probs = self._sigmoid(V[i] @ self.W + self.b)\n",
    "                h = self.rng.binomial(1, h_probs)\n",
    "                v_probs = self._sigmoid(h @ self.W.T + self.a)\n",
    "                v = self.rng.binomial(1, v_probs)\n",
    "            samples[i] = v\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 4/4 [00:00<00:00, 333.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error: 0.163.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 4/4 [00:00<00:00, 499.92it/s]\n",
      "Epoch 2:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 4/4 [00:00<00:00, 333.49it/s]\n",
      "Epoch 3: 100%|██████████| 4/4 [00:00<00:00, 500.08it/s]\n",
      "Epoch 4: 100%|██████████| 4/4 [00:00<00:00, 326.14it/s]\n",
      "Epoch 5: 100%|██████████| 4/4 [00:00<00:00, 333.01it/s]\n",
      "Epoch 6: 100%|██████████| 4/4 [00:00<00:00, 333.41it/s]\n",
      "Epoch 7: 100%|██████████| 4/4 [00:00<00:00, 333.45it/s]\n",
      "Epoch 8: 100%|██████████| 4/4 [00:00<00:00, 66.66it/s]\n",
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 500.41it/s]\n",
      "Epoch 10: 100%|██████████| 4/4 [00:00<00:00, 149.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error: 0.141.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 4/4 [00:00<00:00, 481.94it/s]\n",
      "Epoch 12: 100%|██████████| 4/4 [00:00<00:00, 530.77it/s]\n",
      "Epoch 13: 100%|██████████| 4/4 [00:00<00:00, 461.20it/s]\n",
      "Epoch 14: 100%|██████████| 4/4 [00:00<00:00, 333.49it/s]\n",
      "Epoch 15: 100%|██████████| 4/4 [00:00<00:00, 500.04it/s]\n",
      "Epoch 16: 100%|██████████| 4/4 [00:00<00:00, 500.30it/s]\n",
      "Epoch 17: 100%|██████████| 4/4 [00:00<00:00, 500.17it/s]\n",
      "Epoch 18: 100%|██████████| 4/4 [00:00<00:00, 500.77it/s]\n",
      "Epoch 19: 100%|██████████| 4/4 [00:00<00:00, 500.01it/s]\n",
      "Epoch 20: 100%|██████████| 4/4 [00:00<00:00, 333.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error: 0.106.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 4/4 [00:00<00:00, 500.11it/s]\n",
      "Epoch 22: 100%|██████████| 4/4 [00:00<00:00, 410.62it/s]\n",
      "Epoch 23: 100%|██████████| 4/4 [00:00<00:00, 337.15it/s]\n",
      "Epoch 24: 100%|██████████| 4/4 [00:00<00:00, 455.06it/s]\n",
      "Epoch 25: 100%|██████████| 4/4 [00:00<00:00, 547.02it/s]\n",
      "Epoch 26: 100%|██████████| 4/4 [00:00<00:00, 333.24it/s]\n",
      "Epoch 27: 100%|██████████| 4/4 [00:00<00:00, 500.10it/s]\n",
      "Epoch 28: 100%|██████████| 4/4 [00:00<00:00, 500.54it/s]\n",
      "Epoch 29: 100%|██████████| 4/4 [00:00<00:00, 333.28it/s]\n",
      "Epoch 30: 100%|██████████| 4/4 [00:00<00:00, 499.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error: 0.088.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 4/4 [00:00<00:00, 499.81it/s]\n",
      "Epoch 32: 100%|██████████| 4/4 [00:00<00:00, 500.19it/s]\n",
      "Epoch 33: 100%|██████████| 4/4 [00:00<00:00, 500.20it/s]\n",
      "Epoch 34: 100%|██████████| 4/4 [00:00<00:00, 250.01it/s]\n",
      "Epoch 35: 100%|██████████| 4/4 [00:00<00:00, 500.51it/s]\n",
      "Epoch 36: 100%|██████████| 4/4 [00:00<00:00, 333.34it/s]\n",
      "Epoch 37: 100%|██████████| 4/4 [00:00<00:00, 500.20it/s]\n",
      "Epoch 38: 100%|██████████| 4/4 [00:00<00:00, 500.05it/s]\n",
      "Epoch 39: 100%|██████████| 4/4 [00:00<00:00, 500.13it/s]\n",
      "Epoch 40: 100%|██████████| 4/4 [00:00<00:00, 333.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error: 0.074.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 4/4 [00:00<00:00, 500.11it/s]\n",
      "Epoch 42: 100%|██████████| 4/4 [00:00<00:00, 500.32it/s]\n",
      "Epoch 43: 100%|██████████| 4/4 [00:00<00:00, 500.84it/s]\n",
      "Epoch 44: 100%|██████████| 4/4 [00:00<00:00, 500.13it/s]\n",
      "Epoch 45: 100%|██████████| 4/4 [00:00<00:00, 500.04it/s]\n",
      "Epoch 46: 100%|██████████| 4/4 [00:00<00:00, 500.11it/s]\n",
      "Epoch 47: 100%|██████████| 4/4 [00:00<00:00, 500.16it/s]\n",
      "Epoch 48: 100%|██████████| 4/4 [00:00<00:00, 499.77it/s]\n",
      "Epoch 49: 100%|██████████| 4/4 [00:00<00:00, 500.05it/s]\n",
      "Epoch 50: 100%|██████████| 4/4 [00:00<00:00, 500.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error: 0.057.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 4/4 [00:00<00:00, 999.95it/s]\n",
      "Epoch 52: 100%|██████████| 4/4 [00:00<00:00, 499.84it/s]\n",
      "Epoch 53: 100%|██████████| 4/4 [00:00<00:00, 499.95it/s]\n",
      "Epoch 54: 100%|██████████| 4/4 [00:00<00:00, 499.47it/s]\n",
      "Epoch 55: 100%|██████████| 4/4 [00:00<00:00, 500.19it/s]\n",
      "Epoch 56: 100%|██████████| 4/4 [00:00<00:00, 499.19it/s]\n",
      "Epoch 57: 100%|██████████| 4/4 [00:00<00:00, 500.22it/s]\n",
      "Epoch 58: 100%|██████████| 4/4 [00:00<00:00, 62.50it/s]\n",
      "Epoch 59: 100%|██████████| 4/4 [00:00<00:00, 500.08it/s]\n",
      "Epoch 60: 100%|██████████| 4/4 [00:00<00:00, 499.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error: 0.048.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|██████████| 4/4 [00:00<00:00, 499.93it/s]\n",
      "Epoch 62: 100%|██████████| 4/4 [00:00<00:00, 500.07it/s]\n",
      "Epoch 63: 100%|██████████| 4/4 [00:00<00:00, 500.29it/s]\n",
      "Epoch 64: 100%|██████████| 4/4 [00:00<00:00, 500.02it/s]\n",
      "Epoch 65: 100%|██████████| 4/4 [00:00<00:00, 500.78it/s]\n",
      "Epoch 66: 100%|██████████| 4/4 [00:00<00:00, 499.87it/s]\n",
      "Epoch 67: 100%|██████████| 4/4 [00:00<00:00, 500.16it/s]\n",
      "Epoch 68: 100%|██████████| 4/4 [00:00<00:00, 499.86it/s]\n",
      "Epoch 69: 100%|██████████| 4/4 [00:00<00:00, 499.66it/s]\n",
      "Epoch 70: 100%|██████████| 4/4 [00:00<00:00, 500.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error: 0.031.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71: 100%|██████████| 4/4 [00:00<00:00, 500.20it/s]\n",
      "Epoch 72: 100%|██████████| 4/4 [00:00<00:00, 500.19it/s]\n",
      "Epoch 73: 100%|██████████| 4/4 [00:00<00:00, 333.43it/s]\n",
      "Epoch 74: 100%|██████████| 4/4 [00:00<00:00, 333.51it/s]\n",
      "Epoch 75: 100%|██████████| 4/4 [00:00<00:00, 499.96it/s]\n",
      "Epoch 76: 100%|██████████| 4/4 [00:00<00:00, 1000.43it/s]\n",
      "Epoch 77: 100%|██████████| 4/4 [00:00<00:00, 500.13it/s]\n",
      "Epoch 78: 100%|██████████| 4/4 [00:00<00:00, 499.59it/s]\n",
      "Epoch 79: 100%|██████████| 4/4 [00:00<00:00, 499.95it/s]\n",
      "Epoch 80: 100%|██████████| 4/4 [00:00<00:00, 1000.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error: 0.036.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81: 100%|██████████| 4/4 [00:00<00:00, 500.01it/s]\n",
      "Epoch 82: 100%|██████████| 4/4 [00:00<00:00, 499.98it/s]\n",
      "Epoch 83: 100%|██████████| 4/4 [00:00<00:00, 1000.91it/s]\n",
      "Epoch 84: 100%|██████████| 4/4 [00:00<00:00, 499.49it/s]\n",
      "Epoch 85: 100%|██████████| 4/4 [00:00<00:00, 500.77it/s]\n",
      "Epoch 86: 100%|██████████| 4/4 [00:00<00:00, 500.08it/s]\n",
      "Epoch 87: 100%|██████████| 4/4 [00:00<00:00, 500.26it/s]\n",
      "Epoch 88: 100%|██████████| 4/4 [00:00<00:00, 500.19it/s]\n",
      "Epoch 89: 100%|██████████| 4/4 [00:00<00:00, 500.44it/s]\n",
      "Epoch 90: 100%|██████████| 4/4 [00:00<00:00, 499.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error: 0.023.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91: 100%|██████████| 4/4 [00:00<00:00, 500.13it/s]\n",
      "Epoch 92: 100%|██████████| 4/4 [00:00<00:00, 333.29it/s]\n",
      "Epoch 93: 100%|██████████| 4/4 [00:00<00:00, 333.34it/s]\n",
      "Epoch 94: 100%|██████████| 4/4 [00:00<00:00, 500.16it/s]\n",
      "Epoch 95: 100%|██████████| 4/4 [00:00<00:00, 500.24it/s]\n",
      "Epoch 96: 100%|██████████| 4/4 [00:00<00:00, 499.80it/s]\n",
      "Epoch 97: 100%|██████████| 4/4 [00:00<00:00, 500.38it/s]\n",
      "Epoch 98: 100%|██████████| 4/4 [00:00<00:00, 500.04it/s]\n",
      "Epoch 99: 100%|██████████| 4/4 [00:00<00:00, 499.93it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the alpha_digit data\n",
    "data = read_alpha_digit(file_path=ALPHA_DIGIT_PATH, characters='Z')\n",
    "\n",
    "# Initialize RBM\n",
    "n_visible = data.shape[1]  # Number of visible units (size of each image)\n",
    "n_hidden = 100  # Number of hidden units (hyperparameter)\n",
    "rbm = RBM(n_visible=n_visible, n_hidden=n_hidden, random_state=42)\n",
    "repr(rbm)\n",
    "\n",
    "# Train RBM\n",
    "rbm.train(data, learning_rate=0.1, n_epochs=100, batch_size=10)\n",
    "\n",
    "# Generate samples\n",
    "generated_samples = rbm.generate_image(n_samples=10, n_gibbs_steps=1)\n",
    "\n",
    "# Plot original and generated samples\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 10, i + 1)\n",
    "    plt.imshow(data[i].reshape(20, 16), cmap='gray')\n",
    "    plt.title('Original')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 10, i + 11)\n",
    "    plt.imshow(generated_samples[i].reshape(20, 16), cmap='gray')\n",
    "    plt.title('Generated')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBM(\n",
      "            n_visible=320,\n",
      "            n_hidden=100)\n"
     ]
    }
   ],
   "source": [
    "print(rbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Implementing a Deep Belief Network (DBN) and test on Binary AlphaDigits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBN:\n",
    "    def __init__(self, n_visible: int, hidden_layer_sizes: list[int], random_state=None):\n",
    "        \"\"\"\n",
    "        Initialize the Deep Belief Network.\n",
    "\n",
    "        Parameters:\n",
    "        - n_visible (int): Number of visible units.\n",
    "        - hidden_layer_sizes (list[int]): List of sizes for each hidden layer.\n",
    "        - random_state: Random seed for reproducibility.\n",
    "        \"\"\"\n",
    "        self.n_visible = n_visible\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.rbms = []\n",
    "\n",
    "        # Initialize the first RBM\n",
    "        first_rbm = RBM(\n",
    "            n_visible=n_visible,\n",
    "            n_hidden=hidden_layer_sizes[0],\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        self.rbms.append(first_rbm)\n",
    "\n",
    "        # Initialize RBMs for subsequent hidden layers\n",
    "        for i, size in enumerate(hidden_layer_sizes[1:], start=1):\n",
    "            rbm = RBM(\n",
    "                n_visible=hidden_layer_sizes[i - 1],\n",
    "                n_hidden=size,\n",
    "                random_state=random_state,\n",
    "            )\n",
    "            self.rbms.append(rbm)\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Return a string representation of the DBN object.\n",
    "        \"\"\"\n",
    "        rbm_reprs = [repr(rbm) for rbm in self.rbms]\n",
    "        return f\"DBN(rbms=[{', '.join(rbm_reprs)}])\"\n",
    "\n",
    "\n",
    "    def train(self,\n",
    "        data: np.ndarray,\n",
    "        learning_rate: float = 0.1,\n",
    "        n_epochs: int = 10,\n",
    "        batch_size: int = 10,\n",
    "        print_each=10,\n",
    "    ) -> \"DBN\":\n",
    "        \"\"\"\n",
    "        Train the DBN using Greedy layer-wise procedure.\n",
    "\n",
    "        Parameters:\n",
    "        - data (numpy.ndarray): Input data, shape (n_samples, n_visible).\n",
    "        - learning_rate (float): Learning rate for gradient descent. Default is 0.1.\n",
    "        - n_epochs (int): Number of training epochs. Default is 10.\n",
    "        - batch_size (int): Size of mini-batches. Default is 10.\n",
    "        - print_each: Print reconstruction error each `print_each` epochs.\n",
    "\n",
    "        Returns:\n",
    "        - DBN: Trained DBN instance.\n",
    "        \"\"\"\n",
    "        input_data = data\n",
    "        for rbm in self.rbms:\n",
    "            rbm.train(\n",
    "                input_data,\n",
    "                learning_rate=learning_rate,\n",
    "                n_epochs=n_epochs,\n",
    "                batch_size=batch_size,\n",
    "                print_each=print_each,\n",
    "            )\n",
    "            # Update input data for the next RBM\n",
    "            input_data = rbm.entree_sortie(input_data)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def generate_image(self, n_samples: int = 1, n_gibbs_steps: int = 100) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate samples from the DBN using Gibbs sampling.\n",
    "\n",
    "        Parameters:\n",
    "        - n_samples (int): Number of samples to generate. Default is 1.\n",
    "        - n_gibbs_steps (int): Number of Gibbs sampling steps. Default is 100.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: Generated samples, shape (n_samples, n_visible).\n",
    "        \"\"\"\n",
    "        samples = np.zeros((n_samples, self.n_visible))\n",
    "\n",
    "        # Matrix of initialization value of Gibbs samples for each sample.\n",
    "        V = self.rng.binomial(1, self.rng.random(), size=n_samples * self.n_visible).reshape((n_samples, self.n_visible))\n",
    "        for i in range(n_samples):\n",
    "            for _ in range(n_gibbs_steps):\n",
    "                for rbm in self.rbms:\n",
    "                    h_probs = rbm.entree_sortie(V[i])\n",
    "                    h = self.rng.binomial(1, h_probs)\n",
    "                    v_probs = rbm.sortie_entree(h)\n",
    "                    V[i] = self.rng.binomial(1, v_probs)\n",
    "            samples[i] = V[i]\n",
    "\n",
    "        return samples\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbn = DBN(5, [6, 20, 20, 20, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBN(n_visible=5, hidden_layer_sizes=[6, 20, 20, 20], rbms=[RBM(n_visible=5, n_hidden=6), RBM(n_visible=6, n_hidden=20), RBM(n_visible=20, n_hidden=20), RBM(n_visible=20, n_hidden=20)])\n"
     ]
    }
   ],
   "source": [
    "print(dbn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
